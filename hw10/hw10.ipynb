{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UOsFkZktyIEX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load and preprocess the data\n",
    "\n",
    "We will use data from past 7 days to predict next day temperature.\n",
    "Since every feature has values with varying ranges, we do normalization to confine feature values to a range of [0, 1] before training a neural network. We do this by subtracting the mean and dividing by the standard deviation of each feature.\n",
    "\n",
    "80 % of the data will be used to train the model, i.e. 3650 * 0.8 rows. split_fraction can be changed to alter this percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OEvkGJgSZ1u",
    "outputId": "b14b5557-9374-4d68-cf9f-129621d53f0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-01-01</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-01-02</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-01-03</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-01-04</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-01-05</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Temp\n",
       "0  1981-01-01  20.7\n",
       "1  1981-01-02  17.9\n",
       "2  1981-01-03  18.8\n",
       "3  1981-01-04  14.6\n",
       "4  1981-01-05  15.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('daily-min-temperatures.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1981-01-01\n",
       "1       1981-01-02\n",
       "2       1981-01-03\n",
       "3       1981-01-04\n",
       "4       1981-01-05\n",
       "           ...    \n",
       "3645    1990-12-27\n",
       "3646    1990-12-28\n",
       "3647    1990-12-29\n",
       "3648    1990-12-30\n",
       "3649    1990-12-31\n",
       "Name: Date, Length: 3650, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kNPUajvEar-d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9958783604892041\n",
      "-0.0026863443783818773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize the temperatures\n",
    "df['Temp'] = (df['Temp'] - df['Temp'].mean()) / df['Temp'].std()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Date'], df['Temp'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(y_train.std())\n",
    "print(y_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.3386, 1.6509, 1.8719, 0.8405, 1.1352, 1.1352, 1.1352, 1.5281]),\n",
       " tensor(2.6087))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TempSequenceDataset(Dataset):\n",
    "    def __init__(self, temps, sequence_length=8):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.temps = torch.tensor(temps.values, dtype=torch.float32)\n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "\n",
    "        for i in range(len(self.temps) - sequence_length):\n",
    "            self.samples.append(self.temps[i:i+sequence_length])    # sequence  \n",
    "            self.targets.append(self.temps[i+sequence_length])      # target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.targets[idx]\n",
    "    \n",
    "\n",
    "# Only pass in the normalized temperature column\n",
    "train_dataset = TempSequenceDataset(df['Temp'][:int(len(df)*0.8)])\n",
    "test_dataset = TempSequenceDataset(df['Temp'][int(len(df)*0.8):])\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=None):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM Parameters\n",
    "        self.input_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.forget_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.candidate = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "\n",
    "        self.predictor = nn.Linear(hidden_size, input_size) if output_size is not None else nn.Identity()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "\n",
    "    def init_state_cell(self, batch_size, device):\n",
    "        state = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        cell = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        return state, cell\n",
    "\n",
    "    def forward(self, x, state=None, cell=None):\n",
    "        # Get sequence length and batch size\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "\n",
    "        # Initialize hidden and cell states if not provided\n",
    "        if state is None or cell is None:\n",
    "            state, cell = self.init_state_cell(batch_size, x.device)\n",
    "\n",
    "        # Lists to store outputs and cell states for each time step\n",
    "        outputs = []\n",
    "\n",
    "        # Iterate through the sequence\n",
    "        for t in range(seq_len):\n",
    "            # Input at time step t\n",
    "            xh_t = torch.cat((x[t], state), 1)\n",
    "\n",
    "            # Input gate\n",
    "            inp_t = torch.sigmoid(self.input_gate(xh_t))\n",
    "\n",
    "            # Forget gate\n",
    "            forget_t = torch.sigmoid(self.forget_gate(xh_t))\n",
    "\n",
    "            # Cell state\n",
    "            c_tilda_t = torch.tanh(self.candidate(xh_t))\n",
    "            cell = forget_t * cell + (1-forget_t) * c_tilda_t\n",
    "\n",
    "            # Output gate\n",
    "            ot = torch.sigmoid(self.output(xh_t))\n",
    "\n",
    "            # Hidden state update\n",
    "            state = torch.tanh(cell)\n",
    "\n",
    "            # Normally an LSTM simply outputs the hidden state.\n",
    "            # However, here we want our outputs to be the logits for the predicted next word.\n",
    "            output = self.predictor(state)\n",
    "            outputs.append(output)\n",
    "\n",
    "        # Stack outputs and cell states along the sequence dimension\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        return outputs, (state, cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
