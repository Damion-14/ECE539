{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import re\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time Machine, by H. G. Wells [1898]\n",
      "I\n",
      "The Time Traveller (for so it will be convenient to speak of him)\n",
      "was expounding a recondite matter to us. His grey eyes shone and\n",
      "twinkled, and his usually pale face was flushed and animated. The\n",
      "fire burned brightly, and the soft radiance of the incandescent\n",
      "lights in the lilies of silver caught the bubbles that flashed and\n",
      "passed in our glasses. Our chairs, being his patents, embraced and\n",
      "caressed us rather than submitted to be sat upon, and there was that\n",
      "luxurious after-dinner atmosphere when thought roams gracefully\n"
     ]
    }
   ],
   "source": [
    "corpus = [line.strip() for line in open('TheTimeMachine.txt') if line.strip()]\n",
    "print(\"\\n\".join(corpus[:10]))\n",
    "\n",
    "# Tokenize the sentences into words\n",
    "corpus = [re.sub('[^A-Za-z0-9]+', ' ', line).lower() for line in corpus]\n",
    "corpus = [re.sub(' +', ' ', line) for line in corpus]\n",
    "corpus = [word for line in corpus for word in line.split()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Found 4582 unique words in the provided corpus (of size 32776).\n",
      "  * Created vocabulary from corpus.\n",
      "  * The 10 most common words are the following:\n",
      "[('the', 2261), ('i', 1267), ('and', 1245), ('of', 1155), ('a', 816), ('to', 695), ('was', 552), ('in', 541), ('that', 443), ('my', 440)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "tkn_counter = Counter([word for word in corpus])\n",
    "vocab = {word: idx for idx, (word, _) in enumerate(tkn_counter.most_common(vocab_size))}\n",
    "vocab[\"/UNK\"] = len(vocab)\n",
    "print(f\"  * Found {len(vocab)} unique words in the provided corpus (of size {len(corpus)}).\\n\"\n",
    "      f\"  * Created vocabulary from corpus.\\n\"\n",
    "      f\"  * The 10 most common words are the following:\")\n",
    "print(tkn_counter.most_common(10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random snippet from the corpus.\n",
      "  * Token IDS:\t tensor([ 171,   50,    1,   52,    0,   49, 1176,   36,  133,   13,    1,  377,\n",
      "          14,    4,  506,  697,   85,   18,   20,  855, 2619,    1,    6,   36,\n",
      "           5,  585, 2620,    6, 1632,   59,    4, 1168,   85,    0, 2621,    3,\n",
      "        2622, 2623,   17,    5,  149,    5,    4,  513, 2624,    0, 2625,    3,\n",
      "          82, 1633])\n",
      "  * Words:\t\t space which i or the machine occupied so long as i travelled at a high velocity through time this scarcely mattered i was so to speak attenuated was slipping like a vapour through the interstices of intervening substances but to come to a stop involved the jamming of myself molecule\n"
     ]
    }
   ],
   "source": [
    "class TextCorpusDataset(Dataset):\n",
    "    def __init__(self, corpus, vocab, snippet_len=50):\n",
    "        super().__init__()\n",
    "        self.corpus = corpus\n",
    "        self.snippet_len = snippet_len\n",
    "\n",
    "        # Vocabulary (word-to-index mapping)\n",
    "        self.vocab = vocab\n",
    "\n",
    "        # Inverse vocabulary (index-to-word mapping)\n",
    "        self.inv_vocab = {idx: word for word, idx in self.vocab.items()}\n",
    "\n",
    "    def convert2idx(self, word_sequence):\n",
    "        return [self.vocab[word if word in self.vocab else \"/UNK\"] for word in word_sequence]\n",
    "\n",
    "    def convert2words(self, idx_sequence):\n",
    "        return [self.inv_vocab[idx] for idx in idx_sequence]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.corpus) - self.snippet_len) // self.snippet_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx * self.snippet_len\n",
    "        snippet = self.corpus[idx:idx+self.snippet_len]\n",
    "        snippet = torch.tensor(self.convert2idx(snippet))\n",
    "        return snippet\n",
    "\n",
    "# Test dataset function\n",
    "dataset = TextCorpusDataset(corpus, vocab, snippet_len=50)\n",
    "snippet = dataset[123]\n",
    "print(\"\\nRandom snippet from the corpus.\")\n",
    "print(\"  * Token IDS:\\t\", snippet)\n",
    "print(\"  * Words:\\t\\t\", \" \".join([dataset.inv_vocab[i] for i in snippet.tolist()]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tumulus', 'badly', 'anecdote', 'tumulus', 'tumulus']\n"
     ]
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=None):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM Parameters\n",
    "        self.input_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.forget_gate = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.candidate = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "\n",
    "        self.predictor = nn.Linear(hidden_size, input_size) if output_size is not None else nn.Identity()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "\n",
    "    def init_state_cell(self, batch_size, device):\n",
    "        state = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        cell = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        return state, cell\n",
    "\n",
    "    def forward(self, x, state=None, cell=None):\n",
    "        # Get sequence length and batch size\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "\n",
    "        # Initialize hidden and cell states if not provided\n",
    "        if state is None or cell is None:\n",
    "            state, cell = self.init_state_cell(batch_size, x.device)\n",
    "\n",
    "        # Lists to store outputs and cell states for each time step\n",
    "        outputs = []\n",
    "\n",
    "        # Iterate through the sequence\n",
    "        for t in range(seq_len):\n",
    "            # Input at time step t\n",
    "            xh_t = torch.cat((x[t], state), 1)\n",
    "\n",
    "            # Input gate\n",
    "            inp_t = torch.sigmoid(self.input_gate(xh_t))\n",
    "\n",
    "            # Forget gate\n",
    "            forget_t = torch.sigmoid(self.forget_gate(xh_t))\n",
    "\n",
    "            # Cell state\n",
    "            c_tilda_t = torch.tanh(self.candidate(xh_t))\n",
    "            cell = forget_t * cell + (1-forget_t) * c_tilda_t\n",
    "\n",
    "            # Output gate\n",
    "            ot = torch.sigmoid(self.output(xh_t))\n",
    "\n",
    "            # Hidden state update\n",
    "            state = torch.tanh(cell)\n",
    "\n",
    "            # Normally an LSTM simply outputs the hidden state.\n",
    "            # However, here we want our outputs to be the logits for the predicted next word.\n",
    "            output = self.predictor(state)\n",
    "            outputs.append(output)\n",
    "\n",
    "        # Stack outputs and cell states along the sequence dimension\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        return outputs, (state, cell)\n",
    "\n",
    "hidden_dim, vocab_size = 256, len(dataset.vocab)\n",
    "model = LSTM(vocab_size, hidden_dim, vocab_size).to(device)\n",
    "\n",
    "sentence = \"today is too darn cold\".split()\n",
    "inp = torch.tensor(dataset.convert2idx(sentence), device=device)[:, None]\n",
    "inp = F.one_hot(inp, len(vocab)).float()\n",
    "Yhat, new_state = model(inp)\n",
    "Yhat = Yhat.squeeze(1).argmax(-1)\n",
    "print(dataset.convert2words(Yhat.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'i do not mean to ask you to accept anything to look at times i cannot move at that in'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def generate(prefix, num_preds, model, vocab):\n",
    "    \"\"\"Generates a sentence following the `prefix`.\"\"\"\n",
    "    prefix = torch.tensor(dataset.convert2idx(prefix.split()), device=device).long()\n",
    "\n",
    "    state, cell, outputs = None, None, [prefix[0]]\n",
    "    for i in range(1, len(prefix) + num_preds):\n",
    "        # Prepare one token at a time to feed the model\n",
    "        inp = F.one_hot(outputs[-1], len(vocab)).float()\n",
    "        inp = inp[None, None]\n",
    "\n",
    "        # Compute the prediction for the next token\n",
    "        yhat, (state, cell) = model(inp, state, cell)\n",
    "\n",
    "        if i < len(prefix):\n",
    "            # During warmup (while parsing the prefix), we ignore the model prediction\n",
    "            outputs.append(prefix[i])\n",
    "        else:\n",
    "            # Otherwise, append the model prediction to the output list\n",
    "            yhat = yhat.argmax(dim=-1)[0, 0].long()\n",
    "            outputs.append(yhat)\n",
    "    return ' '.join([dataset.inv_vocab[tkn.item()] for tkn in outputs])\n",
    "\n",
    "generate('i do not mean to ask you to accept anything', 10, model, vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Perplexity 950.7. Loss: 6.857\n",
      "i do not mean to ask you to accept anything the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of\n",
      "Epoch 1 | Perplexity 596.4. Loss: 6.391\n",
      "i do not mean to ask you to accept anything the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of\n",
      "Epoch 2 | Perplexity 487.7. Loss: 6.190\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 3 | Perplexity 403.9. Loss: 6.001\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 4 | Perplexity 336.7. Loss: 5.819\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 5 | Perplexity 284.6. Loss: 5.651\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 6 | Perplexity 241.2. Loss: 5.486\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 7 | Perplexity 205.7. Loss: 5.326\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 8 | Perplexity 173.2. Loss: 5.154\n",
      "i do not mean to ask you to accept anything of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 9 | Perplexity 146.7. Loss: 4.988\n",
      "i do not mean to ask you to accept anything of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 10 | Perplexity 123.0. Loss: 4.812\n",
      "i do not mean to ask you to accept anything of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 11 | Perplexity 102.4. Loss: 4.629\n",
      "i do not mean to ask you to accept anything of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 12 | Perplexity 85.5. Loss: 4.448\n",
      "i do not mean to ask you to accept anything of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 13 | Perplexity 70.9. Loss: 4.261\n",
      "i do not mean to ask you to accept anything of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 14 | Perplexity 58.8. Loss: 4.075\n",
      "i do not mean to ask you to accept anything of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 15 | Perplexity 49.0. Loss: 3.892\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 16 | Perplexity 40.9. Loss: 3.711\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 17 | Perplexity 34.2. Loss: 3.532\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 18 | Perplexity 28.9. Loss: 3.364\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 19 | Perplexity 24.2. Loss: 3.185\n",
      "i do not mean to ask you to accept anything and the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 20 | Perplexity 20.5. Loss: 3.020\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 21 | Perplexity 17.5. Loss: 2.863\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 22 | Perplexity 14.9. Loss: 2.704\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 23 | Perplexity 12.8. Loss: 2.549\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 24 | Perplexity 11.0. Loss: 2.402\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 25 | Perplexity 9.7. Loss: 2.271\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 26 | Perplexity 8.5. Loss: 2.135\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 27 | Perplexity 7.5. Loss: 2.015\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 28 | Perplexity 6.6. Loss: 1.884\n",
      "i do not mean to ask you to accept anything to the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
      "Epoch 29 | Perplexity 5.8. Loss: 1.761\n",
      "i do not mean to ask you to accept anything to the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the\n",
      "Epoch 30 | Perplexity 5.2. Loss: 1.654\n",
      "i do not mean to ask you to accept anything to the time i had been that i had been that i had been that i had been that i had been that i had been that i had been that i had been that i had been that i had been that i had been that i had been\n",
      "Epoch 31 | Perplexity 4.7. Loss: 1.550\n",
      "i do not mean to ask you to accept anything to the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the\n",
      "Epoch 32 | Perplexity 4.3. Loss: 1.454\n",
      "i do not mean to ask you to accept anything to the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the time i was the\n",
      "Epoch 33 | Perplexity 3.8. Loss: 1.345\n",
      "i do not mean to ask you to accept anything to the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the\n",
      "Epoch 34 | Perplexity 3.5. Loss: 1.260\n",
      "i do not mean to ask you to accept anything to the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the\n",
      "Epoch 35 | Perplexity 3.3. Loss: 1.182\n",
      "i do not mean to ask you to accept anything to the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the\n",
      "Epoch 36 | Perplexity 3.0. Loss: 1.106\n",
      "i do not mean to ask you to accept anything to the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the\n",
      "Epoch 37 | Perplexity 2.8. Loss: 1.027\n",
      "i do not mean to ask you to accept anything to the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the time machine and the\n",
      "Epoch 38 | Perplexity 2.6. Loss: 0.965\n",
      "i do not mean to ask you to accept anything to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the\n",
      "Epoch 39 | Perplexity 2.4. Loss: 0.894\n",
      "i do not mean to ask you to accept anything to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the\n",
      "Epoch 40 | Perplexity 2.3. Loss: 0.833\n",
      "i do not mean to ask you to accept anything to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the\n",
      "Epoch 41 | Perplexity 2.2. Loss: 0.772\n",
      "i do not mean to ask you to accept anything to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the\n",
      "Epoch 42 | Perplexity 2.1. Loss: 0.726\n",
      "i do not mean to ask you to accept anything to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the\n",
      "Epoch 43 | Perplexity 2.0. Loss: 0.676\n",
      "i do not mean to ask you to accept anything to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the time machine to the\n",
      "Epoch 44 | Perplexity 1.9. Loss: 0.629\n",
      "i do not mean to ask you to accept anything to the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i\n",
      "Epoch 45 | Perplexity 1.8. Loss: 0.593\n",
      "i do not mean to ask you to accept anything to the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i\n",
      "Epoch 46 | Perplexity 1.7. Loss: 0.552\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 47 | Perplexity 1.7. Loss: 0.517\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 48 | Perplexity 1.6. Loss: 0.486\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 49 | Perplexity 1.6. Loss: 0.452\n",
      "i do not mean to ask you to accept anything to the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i\n",
      "Epoch 50 | Perplexity 1.5. Loss: 0.419\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 51 | Perplexity 1.5. Loss: 0.391\n",
      "i do not mean to ask you to accept anything to the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i was the time machine i\n",
      "Epoch 52 | Perplexity 1.4. Loss: 0.362\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 53 | Perplexity 1.4. Loss: 0.340\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 54 | Perplexity 1.4. Loss: 0.325\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 55 | Perplexity 1.3. Loss: 0.298\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 56 | Perplexity 1.3. Loss: 0.282\n",
      "i do not mean to ask you to accept anything to the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i had finished his face of the time machine i\n",
      "Epoch 57 | Perplexity 1.3. Loss: 0.270\n",
      "i do not mean to ask you to accept anything to the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i\n",
      "Epoch 58 | Perplexity 1.3. Loss: 0.263\n",
      "i do not mean to ask you to accept anything to the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i\n",
      "Epoch 59 | Perplexity 1.3. Loss: 0.238\n",
      "i do not mean to ask you to accept anything to the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i\n",
      "Epoch 60 | Perplexity 1.2. Loss: 0.217\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 61 | Perplexity 1.2. Loss: 0.213\n",
      "i do not mean to ask you to accept anything to the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i\n",
      "Epoch 62 | Perplexity 1.2. Loss: 0.195\n",
      "i do not mean to ask you to accept anything to the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i\n",
      "Epoch 63 | Perplexity 1.2. Loss: 0.188\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 64 | Perplexity 1.2. Loss: 0.186\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 65 | Perplexity 1.2. Loss: 0.165\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 66 | Perplexity 1.2. Loss: 0.156\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 67 | Perplexity 1.2. Loss: 0.160\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 68 | Perplexity 1.2. Loss: 0.147\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 69 | Perplexity 1.2. Loss: 0.141\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 70 | Perplexity 1.1. Loss: 0.135\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 71 | Perplexity 1.1. Loss: 0.127\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 72 | Perplexity 1.1. Loss: 0.120\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 73 | Perplexity 1.1. Loss: 0.116\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 74 | Perplexity 1.1. Loss: 0.121\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time\n",
      "Epoch 75 | Perplexity 1.1. Loss: 0.112\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 76 | Perplexity 1.1. Loss: 0.104\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 77 | Perplexity 1.1. Loss: 0.100\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 78 | Perplexity 1.1. Loss: 0.100\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 79 | Perplexity 1.1. Loss: 0.095\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 80 | Perplexity 1.1. Loss: 0.086\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 81 | Perplexity 1.1. Loss: 0.092\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 82 | Perplexity 1.1. Loss: 0.084\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time machine he know of the time\n",
      "Epoch 83 | Perplexity 1.1. Loss: 0.086\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 84 | Perplexity 1.1. Loss: 0.079\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 85 | Perplexity 1.1. Loss: 0.079\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 86 | Perplexity 1.1. Loss: 0.076\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 87 | Perplexity 1.1. Loss: 0.075\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 88 | Perplexity 1.1. Loss: 0.069\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 89 | Perplexity 1.1. Loss: 0.069\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 90 | Perplexity 1.1. Loss: 0.062\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 91 | Perplexity 1.1. Loss: 0.070\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 92 | Perplexity 1.1. Loss: 0.064\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 93 | Perplexity 1.1. Loss: 0.060\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 94 | Perplexity 1.1. Loss: 0.062\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 95 | Perplexity 1.1. Loss: 0.060\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 96 | Perplexity 1.1. Loss: 0.060\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 97 | Perplexity 1.1. Loss: 0.057\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 98 | Perplexity 1.1. Loss: 0.054\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n",
      "Epoch 99 | Perplexity 1.1. Loss: 0.058\n",
      "i do not mean to ask you to accept anything to a small camera one of the time machine i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will confess i will\n"
     ]
    }
   ],
   "source": [
    "def train_on_sequence(seq, model, optimizer, unroll=5):\n",
    "    \"\"\"Train the model within a batch of long text sequences.\"\"\"\n",
    "    batch_size, num_tokens = seq.shape\n",
    "\n",
    "    total_loss, state, cell = 0., None, None\n",
    "    for i in range(0, num_tokens-unroll-1, unroll):\n",
    "        if state is not None:\n",
    "            state.detach_(), cell.detach_()\n",
    "\n",
    "        # Define the input sequence along which we will unroll the RNN\n",
    "        x = seq[:, i:i+unroll].T\n",
    "        y = seq[:, i+1:i+unroll+1].T\n",
    "\n",
    "        # Forward the model and compute the loss\n",
    "        x = F.one_hot(x, len(vocab)).float()\n",
    "        y_hat, (state, cell) = model(x, state, cell)\n",
    "        l = loss(y_hat.flatten(0, 1), y.flatten(0, 1).long())\n",
    "        total_loss += l.item()\n",
    "\n",
    "        # Backward step (clip gradients to prevent exploding gradients)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    n_batches = (num_tokens-unroll-1) // unroll\n",
    "    return total_loss/n_batches\n",
    "\n",
    "def fit(model, loader, vocab, lr, num_epochs=100, unroll=5):\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr)\n",
    "    test_prompt = 'i do not mean to ask you to accept anything'\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for sequence in loader:\n",
    "            total_loss += train_on_sequence(sequence.to(device), model, optimizer, unroll=unroll)\n",
    "        total_loss /= len(loader)\n",
    "\n",
    "        print(f'Epoch {epoch} | Perplexity {np.exp(total_loss):.1f}. Loss: {total_loss:.3f}')\n",
    "        print(generate(test_prompt, 50, model, vocab))\n",
    "\n",
    "num_epochs, lr = 100, 0.001\n",
    "dataset = TextCorpusDataset(corpus, vocab, 100)\n",
    "loader = DataLoader(dataset, batch_size=32)\n",
    "model = LSTM(len(dataset.vocab), hidden_dim, output_size=len(dataset.vocab)).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "fit(model, loader, dataset.vocab, lr, num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}